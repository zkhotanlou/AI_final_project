{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import unicode_literals\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (3048, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>شرایط حذف ترم چیه؟</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>از کجا می تونم با دکتر وحیدی ارتباط برقرار کنم؟</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>بوفه برداران تا ساعت چند باز است؟</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>کمترین تعداد واحد چند عدد است؟</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>سنگ جامد است</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>سرورای دانشکده مشکل دارن؟</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>کلاس آزمایشگاه فیزیک در دانشکده خودمان برگزار ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>شرایط حذف پزشکی چیه؟</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>در شرایطی ساعت و روز کلاسی جابجا می شود؟</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>سطل آشغال در کلاس 101 وجود ندارد.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              query  label\n",
       "0   0                                 شرایط حذف ترم چیه؟      1\n",
       "1   1    از کجا می تونم با دکتر وحیدی ارتباط برقرار کنم؟      2\n",
       "2   2                  بوفه برداران تا ساعت چند باز است؟      2\n",
       "3   3                     کمترین تعداد واحد چند عدد است؟      1\n",
       "4   4                                       سنگ جامد است      5\n",
       "5   5                          سرورای دانشکده مشکل دارن؟      3\n",
       "6   6  کلاس آزمایشگاه فیزیک در دانشکده خودمان برگزار ...      2\n",
       "7   7                               شرایط حذف پزشکی چیه؟      1\n",
       "8   8           در شرایطی ساعت و روز کلاسی جابجا می شود؟      1\n",
       "9   9                  سطل آشغال در کلاس 101 وجود ندارد.      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('datasets/train.csv')\n",
    "\n",
    "print(\"train shape: {}\".format(train.shape))\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    stop_words=['تر','و','در','به','از','که','این','را','با','است','برای','آن','یک','خود','تا','کرد','بر','هم','نیز','گفت','وی','شد','دارد','ما','اما','یا','شده','باید','هر','آنها','بود','او','یگر','دو','مورد','شود','کند','وجود','بین','پیش','شده_است','پس','نظر','اگر','همه','یکی','حال','هستند','من','کنند','نیست','باشد','چه','بی','می','بخش','همین','افزود','هایی','دارند','راه','همچنین','روی','داد','بیشتر','بسیار','سه','داشت','چند','سوی','تنها','هیچ','میان','اینکه','شدن','بعد','جدید','ولی','حتی','کردن','برخی','کردند','اول','نه','کرده_است','نسبت','بیش','شما','چنین','طور','افراد','تمام','درباره','بار','بسیاری','کرده','چون','ندارد','دوم','بزرگ','طی','حدود','همان','بدون','البته','آنان','دیگری','خواهد_شد','کنیم','قابل','یعنی','رشد','وارد','کل','ویژه','قبل','براساس','نیاز','گذاری','هنوز','لازم','سازی','بوده_است','چرا','وقتی','گرفت','کم','جای','حالی','تغییر','پیدا','اکنون','تحت','باعث','مدت','فقط','زیادی','تعداد','آیا','بیان','رو','شدند','عدم','کرده_اند','بودن','نوع','بلکه','جاری','دهد','برابر','مهم','بوده','اخیر','مربوط','امر','زیر','گیری','شاید','خصوص','آقای','اثر','کننده','بودند','فکر','کنار','اولین','سوم','سایر','کنید','ضمن','مانند','باز','ممکن','حل','دارای','پی','مثل','اجرا','دور','منظور','کسی','موجب','طول','امکان','آنچه','تعیین','گفته','شوند','جمع','خیلی','علاوه','گونه','تاکنون','رسید','ساله','گرفته','شده_اند','علت','چهار','داشته_باشد','خواهد_بود','طرف','تهیه','تبدیل','مناسب','زیرا','مشخص','نزدیک','جریان','روند','بنابراین','یافت','نخستین','بالا','پنج','ریزی','عالی','چیزی','نخست','بیشتری','ترتیب','شده_بود','خاص','خوبی','خوب','شروع','فرد','کامل','غیر','دهند','آخرین','دادن','جدی','بهترین','شامل','گیرد','بخشی','باشند','تمامی','بهتر','داده_است','حد','نبود','کسانی','داریم','علیه','دانست','ناشی','داشتند','دهه','ایشان','آنجا','گرفته_است','دچار','لحاظ','آنکه','داده','بعضی','هستیم','اند','برداری','نباید','نشست','سهم','همیشه','آمد','اش','وگو','حداقل','طبق','جا','خواهد_کرد','نوعی','چگونه','رفت','هنگام','فوق','روش','ندارند','سعی','بندی','شمار','کلی','کافی','مواجه','همچنان','زیاد','سمت','کوچک','داشته_است','چیز','پشت','آورد','حالا','روبه','دادند','عهده','نیمه','جایی','دیگران','سی','بروز','یکدیگر','آمده_است','جز','کنم','سپس','کنندگان','خودش','چیه','چیست','همواره','یافته','شان','صرف','رسیدن','چهارم','یابد','متر','ساز','داشته','کرده_بود','باره','نحوه','کردم','تو','شخصی','داشته_باشند','محسوب','پخش','کمی','متفاوت','سراسر','کاملا','داشتن','نظیر','آمده','گروهی','فردی','ع','همچون','خطر','خویش','کدام','دسته','سبب','عین','آوری','متاسفانه','بیرون','دار','ابتدا','شش','افرادی','سالهای','درون','نیستند','یافته_است','تو','هام','پر','خاطرنشان','گاه','','جمعی','اغلب','دوباره','لذا','زاده','فر','گردد','اینجا']\n",
    "    normalizer = Normalizer()\n",
    "    tokenizer = WordTokenizer(join_verb_parts=False)\n",
    "    informal_normalizer = InformalNormalizer()\n",
    "    stemmer = Stemmer()\n",
    "    lemmatizer = Lemmatizer()\n",
    "    \n",
    "    def remove_special_chars(self,text):\n",
    "        chars=['0','1','2','3','4','5','6','7','8','9','\"',\"'\",'=','@','&','%','.',',',':','\\\\','$','^','<','>','!','؟','،','.',':','!','?','{','}',';','\\n','\\t','(',')','[',']','/','*','+','#','\\u200c','\\ufeff','-','_','|','۱','۲','۳','۴','۵','۶','۷','۸','۹','۰','،']\n",
    "        for item in chars:\n",
    "            text=text.replace(item,\"\")\n",
    "        return text \n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        cleaned_text = self.normalizer.punctuation_spacing(text)\n",
    "        cleaned_text = self.normalizer.affix_spacing(cleaned_text)\n",
    "        cleaned_text = self.normalizer.character_refinement(cleaned_text)\n",
    "        cleaned_text = self.remove_special_chars(cleaned_text)\n",
    "        cleaned_text = self.normalizer.normalize(cleaned_text)\n",
    "        \n",
    "        \n",
    "        return cleaned_text\n",
    "\n",
    "    def make_tokens(self, text):\n",
    "        tokenized = [self.lemmatizer.lemmatize(token)\n",
    "                    for token in self.tokenizer.tokenize(text) \n",
    "                    if token not in self.stop_words]\n",
    "        return tokenized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "The following are the basic steps involved in performing the random forest algorithm:\n",
    "\n",
    "1.Pick N random records from the dataset.\n",
    "\n",
    "2.Build a decision tree based on these N records.\n",
    "\n",
    "3.Choose the number of trees you want in your algorithm and repeat steps 1 and 2.\n",
    "\n",
    "4.The final value can be calculated by taking the average of all the values predicted by all the trees in forest. Or, in case of a classification problem, each tree in the forest predicts the category to which the new record belongs. Finally, the new record is assigned to the category that wins the majority vote.\n",
    "\n",
    "### Advantages of using Random Forest\n",
    "As with any algorithm, there are advantages and disadvantages to using it.\n",
    "\n",
    "1.The random forest algorithm is not biased, since, there are multiple trees and each tree is trained on a subset of data. Basically, the random forest algorithm relies on the power of \"the crowd\"; therefore the overall biasedness of the algorithm is reduced.\n",
    "\n",
    "2.This algorithm is very stable. Even if a new data point is introduced in the dataset the overall algorithm is not affected much since new data may impact one tree, but it is very hard for it to impact all the trees.\n",
    "\n",
    "3.The random forest algorithm works well when you have both categorical and numerical features.\n",
    "\n",
    "4.The random forest algorithm also works well when data has missing values or it has not been scaled well\n",
    "\n",
    "## Finding TFIDF\n",
    "The bag of words approach works fine for converting text to numbers. However, it has one drawback. It assigns a score to a word based on its occurrence in a particular document. It doesn't take into account the fact that the word might also be having a high frequency of occurrence in other documents as well. TFIDF resolves this issue by multiplying the **term frequency of a word** by the **inverse document frequency**. The TF stands for \"Term Frequency\" while IDF stands for \"Inverse Document Frequency\".\n",
    "\n",
    "#### Term frequency is calculated as:\n",
    "\n",
    "Term frequency = (Number of Occurrences of a word)/(Total words in the document)\n",
    "\n",
    "#### Inverse Document Frequency is calculated as:\n",
    "\n",
    "IDF(word) = Log((Total number of documents)/(Number of documents containing the word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocess()\n",
    "train['query'] = train.apply(lambda x: preprocess.clean_text(x['query']) , axis = 1)\n",
    "\n",
    "def k_fold_validation(k, data):\n",
    "    \n",
    "    kfold = KFold(n_splits=k, random_state=0)\n",
    "    score = []\n",
    " \n",
    "    for train_index , test_index in kfold.split(train[['query']]):\n",
    "    \n",
    "        X_train , X_test = train['query'].iloc[train_index] , train['query'].iloc[test_index]\n",
    "        y_train , y_test = train['label'].iloc[train_index] , train['label'].iloc[test_index]\n",
    "    \n",
    "        vectorizer = TfidfVectorizer(min_df= 3, stop_words=preprocess.stop_words, sublinear_tf=True)\n",
    "        features = vectorizer.fit_transform(X_train)\n",
    "        \n",
    "        classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "        classifier.fit(features, y_train) \n",
    "\n",
    "        y_pred = classifier.predict(vectorizer.transform(X_test))\n",
    "        score.append(precision_recall_fscore_support(y_pred , y_test, average='weighted'))\n",
    "   \n",
    "    avg_prec_score = sum([ i[0] for i in score])/k \n",
    "    avg_recall_score = sum([ i[1] for i in score])/k \n",
    "    avg_fscore_score = sum([ i[2] for i in score])/k \n",
    "    return avg_prec_score, avg_recall_score, avg_fscore_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zahra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg precision : 0.7121474777896198\n",
      "Avg recall : 0.7119422572178477\n",
      "Avg fscore : 0.7091010343052379\n"
     ]
    }
   ],
   "source": [
    "avg_prec_score, avg_recall_score, avg_fscore_score = k_fold_validation(3,train)\n",
    "print('Avg precision : {}'.format(avg_prec_score))\n",
    "print('Avg recall : {}'.format(avg_recall_score))\n",
    "print('Avg fscore : {}'.format(avg_fscore_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Random Forest and Naive Bayes Classifier\n",
    "Random Forest Classifier gained less metrics scores in comparison to Naive Bayes classifier.\n",
    "Actually it sounds that porecessing on persian language has an impact on this difference because in naive bayes algorithm some processes had been done on our data wich it causes to have sutable data for training. Althought Random Forest Classifier is a good choice for this project but as it works with lots of random selected parts for making decision trees it may cause to have a litle more faults in predicting the test data. On the other hand naive bayes classifier works based on Bayes' Theorem and calculate a probability for containing to each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier\n",
    "Logistic regression is a regression model. The model builds a regression model to predict the probability that a given data entry belongs to the category numbered as “1”. Just like Linear regression assumes that the data follows a linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg precision : 0.7420202344563722\n",
      "Avg recall : 0.7355643044619423\n",
      "Avg fscore : 0.7369400561302211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def k_fold_validation_logistic(k, data):\n",
    "    \n",
    "    kfold = KFold(n_splits=k, random_state=None)\n",
    "    score = []\n",
    " \n",
    "    for train_index , test_index in kfold.split(train[['query']]):\n",
    "    \n",
    "        X_train , X_test = train['query'].iloc[train_index] , train['query'].iloc[test_index]\n",
    "        y_train , y_test = train['label'].iloc[train_index] , train['label'].iloc[test_index]\n",
    "    \n",
    "        vectorizer = TfidfVectorizer(min_df= 3, stop_words=preprocess.stop_words, sublinear_tf=True, norm='l2')\n",
    "        features = vectorizer.fit_transform(X_train)\n",
    "        \n",
    "        clf = LogisticRegression(random_state=0).fit(features, y_train)\n",
    "        y_pred = clf.predict(vectorizer.transform(X_test))\n",
    "        \n",
    "        score.append(precision_recall_fscore_support(y_pred , y_test, average='weighted'))\n",
    "   \n",
    "    avg_prec_score = sum([ i[0] for i in score])/k \n",
    "    avg_recall_score = sum([ i[1] for i in score])/k \n",
    "    avg_fscore_score = sum([ i[2] for i in score])/k \n",
    "                             \n",
    "    return avg_prec_score, avg_recall_score, avg_fscore_score\n",
    "                             \n",
    "\n",
    "                             \n",
    "                             \n",
    "avg_prec_score, avg_recall_score, avg_fscore_score = k_fold_validation_logistic(3,train)\n",
    "print('Avg precision : {}'.format(avg_prec_score))\n",
    "print('Avg recall : {}'.format(avg_recall_score))\n",
    "print('Avg fscore : {}'.format(avg_fscore_score))                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
